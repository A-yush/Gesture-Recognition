# Melanoma skin cancer Detection
> Building a neural network which correctly identifies the gestures in the form of video frames. It is a multiclass classification problem.

## Table of Contents
* [Problem Statement](#problem-statement)
* [Dataset](#dataset)
* [CNN Architecture Design](#cnn-design)
* [Model Architecture](#model-architecture)
* [Model Evaluation](#model-evaluation)
* [Result](#result)
* [References](#references)
* [Technologies Used](#technologies-used)
* [Contact](#contact)


## Problem Statement
Developing a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. 

## Dataset
The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:

1. Thumbs up:  Increase the volume
2. Thumbs down: Decrease the volume
3. Left swipe: 'Jump' backwards 10 seconds
4. Right swipe: 'Jump' forward 10 seconds  
5. Stop: Pause the movie

The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use. 

The data is in a zip file. The zip file contains a 'train' and a 'val' folder with two CSV files for the two folders. These folders are in turn divided into subfolders where each subfolder represents a video of a particular gesture. Each subfolder, i.e. a video, contains 30 frames (or images). Note that all images in a particular video subfolder have the same dimensions but different videos may have different dimensions. Specifically, videos have two types of dimensions - either 360x360 or 120x160 (depending on the webcam used to record the videos).

Each row of the CSV file represents one video and contains three main pieces of information - the name of the subfolder containing the 30 images of the video, the name of the gesture and the numeric label (between 0-4) of the video.

Download the data from references.

## CNN Architecture Design
To classify skin cancer using skin lesions images. To achieve higher accuracy and results on the classification task, I have built custom CNN model.

- Rescalling Layer - To rescale an input in the [0, 255] range to be in the [0, 1] range.
- Convolutional Layer - Convolutional layers apply a convolution operation to the input, passing the result to the next layer. A convolution converts all the pixels in its receptive field into a single value. For example, if you would apply a convolution to an image, you will be decreasing the image size as well as bringing all the information in the field together into a single pixel. 
- Pooling Layer - Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.
- Dropout Layer - The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.
- Flatten Layer - Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.
- Dense Layer - The dense layer is a neural network layer that is connected deeply, which means each neuron in the dense layer receives input from all neurons of its previous layer.
- Activation Function(ReLU) - The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.
- Activation Function(Softmax) - The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. The main advantage of using Softmax is the output probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one.

## Model Architecture

![model-architecture](https://github.com/A-yush/Gesture-Recognition/blob/master/images/Conv3D-structure.png)

## Model Evaluation

![model-evaluation](https://github.com/A-yush/Gesture-Recognition/blob/master/images/train-val-accuracy.png)

## Result
- Training categorical loss = 0.2606
- Training categorical accuracy = 0.9035
- Validation categorical loss = 0.3139
- Validation categorical accuracy: 0.8900

## References
Data : https://drive.google.com/uc?id=1ehyrYBQ5rbQQe6yL4XbLWe3FMvuVUGiL

## Technologies Used
- Tensorflow - 2.3.4
- Numpy - 1.19.5
- Pandas - 1.1.5
- Sklearn
- Imageio
- Keras

## Contact
Created by [@A-yush] - feel free to contact me!